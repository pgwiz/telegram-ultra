# Hermes Worker & IPC Protocol — Developer Guide

## Overview

The Python worker is a persistent subprocess spawned by the Rust bot.
It receives download/search requests via stdin, performs the heavy work (yt-dlp, ffmpeg, ZIP archiving), and streams progress + results back via stdout.

**Entry point:** Run as `python -m worker.application` from the project root.
**Managed by:** `bot/src/workers/python_dispatcher.rs`

---

## IPC Protocol

### Transport

```
Bot (Rust)          Worker (Python)
    │  ──── JSON line ──>  │   stdin
    │  <── JSON line ────  │   stdout
    │                      │   stderr → tracing::warn!(target: "python_worker")
```

- One JSON object per line (`\n` delimited)
- Bot writes requests to worker's **stdin**
- Worker writes responses (progress, done, error) to **stdout**
- Worker logs to **stderr** (forwarded to Rust tracing, not parsed)
- Bot's `PythonDispatcher` routes responses to the correct task channel by `task_id`

---

### Request Schema (Rust → Python)

```json
{
  "task_id": "c4a1f2e8-...",
  "action": "youtube_dl",
  "url": "https://youtu.be/dQw4w9WgXcQ",
  "params": {
    "extract_audio": true,
    "audio_format": "mp3",
    "output_dir": "./downloads/123456/c4a1f2e8",
    "archive_max_size_mb": 100
  }
}
```

| Field | Type | Description |
|-------|------|-------------|
| `task_id` | string | UUID generated by bot; used to route responses |
| `action` | string | Handler name (snake_case, see actions table below) |
| `url` | string? | Media URL (omitted for non-URL actions) |
| `params` | object | Action-specific parameters |

---

### Response Schema (Python → Rust)

```json
{
  "task_id": "c4a1f2e8-...",
  "event": "progress",
  "data": { "percent": 45, "speed": "1.2MB/s", "eta": 30, "status": "downloading" }
}
```

| Field | Type | Description |
|-------|------|-------------|
| `task_id` | string | Mirrors back the request task_id |
| `event` | string | Event type (see events table below) |
| `data` | object | Event-specific payload |

---

### IPC Actions

| Action | `IPCAction` variant | Handler (Python) | Purpose |
|--------|---------------------|------------------|---------|
| `youtube_dl` | `YoutubeDl` | `handle_youtube_download` | Download single video or audio |
| `youtube_search` | `YoutubeSearch` | `handle_youtube_search` | Search YouTube, return result list |
| `get_video_info` | `GetVideoInfo` | `handle_get_video_info` | Fetch title, thumbnail, duration |
| `get_formats` | `GetFormats` | `handle_get_formats` | List available formats for a URL |
| `playlist` | `Playlist` | `handle_playlist_download` | Download playlist, archive to ZIP |
| `cache_cleanup` | `CacheCleanup` | inline lambda | Remove expired search cache entries |
| `cache_stats` | `CacheStats` | inline lambda | Return cache statistics |
| `health_check` | `HealthCheck` | inline lambda | Liveness probe, returns config info |

---

### IPC Events (Response types)

| Event | Python call | Rust `IPCEvent` | When |
|-------|-------------|-----------------|------|
| `progress` | `send_progress()` | `Progress` | During download (0-100%) |
| `done` | `send_response('done', ...)` | `Done` | Download/action complete |
| `error` | `send_error()` | `Error` | Handler failure |
| `search_results` | `send_response('search_results', ...)` | `SearchResults` | Search results ready |
| `video_info` | `send_response('video_info', ...)` | `VideoInfo` | Video metadata fetched |
| `format_list` | `send_response('format_list', ...)` | `FormatList` | Available formats listed |
| `health_ok` | `send_response('health_ok', ...)` | `HealthOk` | Health check response |
| `cache_stats` | `send_response('cache_stats', ...)` | `CacheStats` | Cache statistics |
| `cache_cleanup_done` | `send_response('cache_cleanup_done', ...)` | `CacheCleanupDone` | Cache purge complete |

---

### `done` Event Data

```json
{
  "files": [
    { "path": "/abs/path/to/song.mp3", "size": 4194304 }
  ],
  "title": "Never Gonna Give You Up",
  "duration": 213
}
```

### `error` Event Data

```json
{
  "message": "yt-dlp exited with code 1: Video unavailable",
  "error_code": "YTDLP_ERROR"
}
```

---

## Request Builders (Rust side)

In `shared/src/ipc_protocol.rs`:

```rust
// Single video — audio
download_request(task_id, url, extract_audio=true, out_dir)
// Playlist — with limit and format
playlist_request_opts(task_id, url, out_dir, max_items=Some(25), extract_audio=false)
// Search
search_request(task_id, query, max_results=5)
// Get formats
get_formats_request(task_id, url)
// Health check
health_check_request(task_id)
```

All use the `IPCRequest::new(task_id, action).with_url(...).with_params(...)` builder chain.

---

## Worker Startup Sequence

```
python -m worker.application
  1. logging.basicConfig → stderr
  2. get_database() → SQLite migrations (task status tracking)
  3. CacheManager.get_stats() → search cache warmup
  4. cookie_manager.verify_on_startup() → check cookies.txt exists
  5. setup_handlers() → register all 8 IPC handlers
  6. ipc_handler.run() → blocking stdin loop
```

On stdin EOF (bot closes stdin): worker logs stats and exits cleanly.
On bot crash/kill: Python process receives SIGTERM and exits.

---

## youtube_dl Handler

**File:** `worker/youtube_dl.py`
**Action:** `youtube_dl`

**Params used:**

| Param | Default | Description |
|-------|---------|-------------|
| `extract_audio` | `false` | If true, extract audio and convert to mp3/m4a |
| `audio_format` | `"mp3"` | `"mp3"` or `"m4a"` |
| `output_dir` | required | Directory to write output files |
| `format` | auto | yt-dlp format string (e.g. `"bestaudio"`) |

**Flow:**
1. Build yt-dlp options dict (cookies, format, output template, progress hooks)
2. Run `yt_dlp.YoutubeDL(opts).download([url])` — blocking subprocess
3. Progress hook fires `send_progress()` events
4. Scan `output_dir` for output files
5. Send `done` event with file list

**Audio quality logic:**
- Files under `BEST_AUDIO_LIMIT_MB` → try `bestaudio` first
- Larger files → fall back to limited bitrate format
- After download, if extract_audio and file is not mp3: run ffmpeg conversion

---

## playlist_dl Handler

**File:** `worker/playlist_dl.py`
**Action:** `playlist`

**Params used:**

| Param | Default | Description |
|-------|---------|-------------|
| `extract_audio` | `true` | Audio or video |
| `audio_format` | `"mp3"` | Audio container format |
| `output_dir` | required | Per-task output directory |
| `playlist_end` | all | Max number of tracks to download |
| `archive_max_size_mb` | `100` | ZIP split size |

**Flow:**
1. Fetch playlist info (title, count) with `--flat-playlist`
2. Send initial progress (0%)
3. Download tracks one by one, updating progress after each
4. Collect all downloaded files
5. If total size > `archive_max_size_mb`: split into multiple ZIPs
6. Otherwise: pack all into a single ZIP
7. Send `done` with ZIP file path(s)

**ZIP naming:**
```
{sanitized_playlist_title}.zip
{sanitized_playlist_title}.part1.zip  (if split)
{sanitized_playlist_title}.part2.zip
```

---

## youtube_search Handler

**File:** `worker/youtube_search.py`
**Action:** `youtube_search`

**Params:**
- `query`: search string
- `max_results` (default: 5): number of results

Uses yt-dlp's `ytsearch{N}:query` prefix to fetch metadata without downloading.
Results are cached in SQLite (`search_cache` table) for `CACHE_EXPIRY_HOURS` hours.

**Response event:** `search_results`
```json
{
  "results": [
    {
      "video_id": "dQw4w9WgXcQ",
      "title": "Never Gonna Give You Up",
      "url": "https://www.youtube.com/watch?v=dQw4w9WgXcQ",
      "duration": 213,
      "thumbnail": "https://i.ytimg.com/vi/.../hqdefault.jpg",
      "channel": "RickAstleyVEVO",
      "view_count": 1400000000
    }
  ]
}
```

---

## Configuration (`worker/config.py`)

`WorkerConfig` is a Python dataclass. All fields read from env vars at import time.
A global singleton `config = WorkerConfig()` is used everywhere.

| Env Var | Default | Description |
|---------|---------|-------------|
| `YOUTUBE_COOKIE_FILE` | `./cookies.txt` | yt-dlp cookie file (for age-gated/private videos) |
| `BEST_AUDIO_LIMIT_MB` | `15` | Threshold for best-audio vs limited-bitrate fallback |
| `NODE_BIN` | auto | Node.js binary path (for yt-dlp JS challenges) |
| `MAX_RETRIES` | `3` | Download retry count |
| `RETRY_DELAY_SECONDS` | `5` | Delay between retries |
| `YT_TIMEOUT` | `300` | yt-dlp subprocess timeout (secs) |
| `IPC_TIMEOUT` | `600` | Total IPC task timeout (secs) |
| `DOWNLOAD_DIR` | `./downloads` | Root output directory |
| `TEMP_DIR` | `./temp` | Temp files (intermediate conversions) |
| `ENABLE_SEARCH_CACHE` | `true` | Whether to cache search results |
| `CACHE_EXPIRY_HOURS` | `24` | Search cache TTL |
| `ARCHIVE_MAX_SIZE_MB` | `100` | Max ZIP size before splitting |
| `ARCHIVE_COMPRESSION_LEVEL` | `6` | ZIP compression level (0-9) |
| `PLAYLIST_NAME_MAX_LENGTH` | `100` | Max chars in playlist ZIP filename |
| `RATE_LIMIT_SEARCHES_PER_HOUR` | `60` | Search rate limit |
| `LOG_LEVEL` | `info` | Python logging level |

---

## Progress Hook

**File:** `worker/progress_hooks.py`

yt-dlp calls the hook dict with status updates during download:

```python
def make_progress_hook(ipc, task_id):
    def hook(d):
        if d['status'] == 'downloading':
            percent = parse_percent(d.get('_percent_str', '0%'))
            speed = d.get('_speed_str', '')
            eta = d.get('eta', 0)
            ipc.send_progress(task_id, percent, speed, eta, 'downloading')
        elif d['status'] == 'finished':
            ipc.send_progress(task_id, 95, '', 0, 'processing')  # post-process step
    return hook
```

The Rust side renders progress as a bar in the Telegram message:
```
▓▓▓▓▓▓░░░░ 60% · 1.2MB/s · ETA 45s
```

---

## TaskQueue (Rust, shared crate)

**File:** `shared/src/task_queue.rs`

Limits concurrent downloads across all users with a Tokio semaphore.

```
task_queue.enqueue(task_id, chat_id, "youtube_dl")   // register, returns false if duplicate
task_queue.acquire(task_id)                           // wait for semaphore slot (blocks if at capacity)
task_queue.update_progress(task_id, 45, "1.2MB/s")   // update metadata
task_queue.complete(task_id)                          // release slot
task_queue.fail(task_id)                              // release slot, mark failed
task_queue.cancel(task_id)                            // release slot if held, mark cancelled
```

Default max concurrent: `3` (set via `MAX_CONCURRENT_TASKS` env var).
`TaskState`: `Queued` → `Running` → `Done` / `Failed` / `Cancelled`

---

## Adding a New Handler

To add a new IPC action (e.g., `audio_convert`):

**1. Python side — create handler**
```python
# worker/audio_convert.py
async def handle_audio_convert(ipc, task_id, request):
    url = request.get('url')
    params = request.get('params', {})
    # ... do work ...
    ipc.send_progress(task_id, 50, '', 0, 'converting')
    # ... finish ...
    ipc.send_response(task_id, 'done', {'files': [...]})
```

**2. Register in `worker/application.py`**
```python
from worker.audio_convert import handle_audio_convert
ipc_handler.register('audio_convert', handle_audio_convert)
```

**3. Rust side — add variant to `IPCAction`**
```rust
// shared/src/ipc_protocol.rs
pub enum IPCAction {
    // ...existing...
    AudioConvert,
}
```

**4. Add request builder (optional)**
```rust
pub fn audio_convert_request(task_id: &str, url: &str, out_dir: &str) -> IPCRequest {
    IPCRequest::new(task_id, IPCAction::AudioConvert)
        .with_url(url)
        .with_params(serde_json::json!({ "output_dir": out_dir }))
}
```

**5. Call from bot command handler in `commands.rs`**

The dispatcher routes responses by `task_id` automatically — no other changes needed.
